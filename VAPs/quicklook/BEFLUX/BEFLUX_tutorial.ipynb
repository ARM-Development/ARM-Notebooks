{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70840257-70e4-45e2-b491-14bff5a257a3",
   "metadata": {},
   "source": [
    "# BEFLUX1LONG.C1 Notebook\n",
    "\n",
    "[Click here](https://www.arm.gov/capabilities/vaps/beflux) for more information about this vap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97097763",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate the workflow to explore ARM vap data (using beflux1long as an example.) Value-added products (VAPs) are higher-order data products that have been analyzed and processed to ease scientistsâ€™ use of ARM data in atmospheric research and global climate models. \n",
    "Here is the main content we will cover."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddec40f",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "## Access the data\n",
    "* How to retrieve the data\n",
    "* Data path and file name conventions\n",
    "* Load data\n",
    "## Explore the data\n",
    "* NetCDF Data structure\n",
    "* Xarray essentials\n",
    "* Xarray Variable\n",
    "## Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460fd89f-e034-452c-b837-f65c5958264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import act\n",
    "import xarray as xr\n",
    "\n",
    "import random\n",
    "\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372d5be",
   "metadata": {},
   "source": [
    "## Access the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0d9684",
   "metadata": {},
   "source": [
    "### How to retrieve the data\n",
    "We assume the path \"/data/archive\" is available where you are running this notebook. You can use `os.path.exists(\"/data/archive\")` to verify if the path exists at your machine.\n",
    "\n",
    "\n",
    "### Data path and file name conventions\n",
    "There several common terminologies regarding ARM data, for example, data-stream-name, data-level, site, facility, instrument, etc. (For more details, please see [ARM Data File Standards Version 1.2](https://www.google.com/search?q=arm+datastream+facility+cite+definition&rlz=1C1GCEJ_enUS1029US1029&ei=hb41ZICrBPukqtsPvMODIA&ved=0ahUKEwjAgeiS0aL-AhV7kmoFHbzhAAQQ4dUDCBA&uact=5&oq=arm+datastream+facility+cite+definition&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIFCAAQogQyBQgAEKIEMgUIABCiBDIFCAAQogQyBQgAEKIEOgoIABBHENYEELADOgoIIRCgARDDBBAKSgQIQRgAUJ4DWIoOYO0PaAFwAXgAgAGMAYgBuQmSAQMyLjmYAQCgAQHIAQjAAQE&sclient=gws-wiz-serp).) \n",
    "\n",
    "For example, this notebook is called `beflux1long.c1`, where `beflux1long` is the \"datastream name\", and the `{process.ds_class_level}}` is the \"data level\".\n",
    "\n",
    "This datastream also contains site `sgp` and facility `C1`. (Note: individual datastream might have multiple site-facility pairs.)\n",
    "In such a case, the data of this data-stream is stored at `/data/archive/sgp/sgpbeflux1longC1.c1`, which is in the format of `<DATA_DIR>/<site>/<site><DATASTREAM_NAME><facility>.<DATA_LEVEL>`. We can use the following method to assign the data-stream directory `datastream_dir = os.path.join(DATA_DIR, site, site + DATASTREAM_NAME + facility + '.' + DATA_LEVEL )`\n",
    "\n",
    "The data files under datastream_dir also follows naming conventions. But once reach the datastream_dir level, the most import file naming convention to differentiate the files is \"yyyyMMdd.hhmmss\", which comes handy to filter out files based on datetime. For example, we can use `glob.glob(f'{datastream_dir}/*.200709*.*')` to filter files in 2007 September.\n",
    "\n",
    "(Note: refer to the https://adc.arm.gov/discovery/#/ and https://adc.arm.gov/solr8/metadata/select API to explore ARM datastream and assoicated available sites and facilities\n",
    "\n",
    "Please see the following examples in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e9eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify if DATA_DIR path exists\n",
    "DATA_DIR = \"/data/archive\"\n",
    "os.path.exists(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586993fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speicify datastream_dir following the path conventions and check its existence\n",
    "DATASTREAM_NAME = \"beflux1long\"\n",
    "DATA_LEVEL = \"c1\"\n",
    "site = \"sgp\"\n",
    "facility = \"C1\"\n",
    "datastream_dir = os.path.join(DATA_DIR, site, site + DATASTREAM_NAME + facility + '.' + DATA_LEVEL )\n",
    "print(datastream_dir)\n",
    "print(os.path.exists(datastream_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742f7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus: list 5 (random) files under datastream_dir\n",
    "files = os.listdir(datastream_dir)\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b98a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus: get most recent file\n",
    "list_of_files = glob.glob(f\"{datastream_dir}/*\") # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "latest_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus sort datastream files based on datetime\n",
    "files = os.listdir(datastream_dir)\n",
    "file_sorted = files.copy()\n",
    "file_sorted.sort()  \n",
    "print(file_sorted[:5])\n",
    "\n",
    "# to reverse\n",
    "file_sorted_reverse = files.copy()  \n",
    "file_sorted_reverse.sort(reverse=True)\n",
    "print(file_sorted_reverse[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5923b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus: pattern matching\n",
    "# filter the 200709** files under datastream_dir\n",
    "files_filter = glob.glob(f'{datastream_dir}/*.200709*.*')\n",
    "files_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus: use armnotebook_utils.file_filter (TODO) to filter files based on datastream info \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeb9efc",
   "metadata": {},
   "source": [
    "### Load data\n",
    "The arm data is stored in [NetCDF](https://en.wikipedia.org/wiki/NetCDF#:~:text=%22NetCDF%20(network%20Common%20Data%20Form,format%20for%20representing%20scientific%20data.) format. We can use xarray's `open_dataset` method to load single file, or `open_mfdataset` to open multiple files. (Note: the latter will still return a single xarray dataset object by combining multiple files.)\n",
    "\n",
    "Note: open_dataset keeps the file handle open and lazy loads its contents. All parameters are passed directly to open_dataset. It is a preferable method over load_dataset for memory-effiency. (more details, please see [xarray.open_dataset](https://docs.xarray.dev/en/stable/generated/xarray.open_dataset.html))\n",
    "\n",
    "See the following example in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a440a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open single file\n",
    "full_path = latest_file\n",
    "print(full_path)\n",
    "ds_single = xr.open_dataset(full_path)\n",
    "ds_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0143a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_single)\n",
    "print(type(ds_single))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f8939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open multiple files\n",
    "n_files = 3\n",
    "full_paths = [os.path.join(datastream_dir, f_path)  for f_path in file_sorted_reverse[:n_files]]\n",
    "print(full_paths)\n",
    "try: # Note: sometimes multiple files cannot be merged, so we used try except here.\n",
    "    ds_mutiple = xr.open_mfdataset(full_paths)\n",
    "    # ds_mutiple\n",
    "    print(type(ds_mutiple))\n",
    "    print(ds_mutiple)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa59943",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f69b9",
   "metadata": {},
   "source": [
    "### NetCDF Data structure \n",
    "\n",
    "\n",
    "(If you are confident with NetCDF basics and xarray essentials, feel free to skip this session.)\n",
    "Before we dive into data exploration, there are some eseential concpets we should be familiar with (shown below): \n",
    "* Dataset\n",
    "* Data array\n",
    "* Variable\n",
    "* Dimenssion\n",
    "* Coordinate\n",
    "* Data Type\n",
    "* Meta Data (Attributes)\n",
    "\n",
    "We will not go into details about NetCDF basics and here are some references you might find helpful\n",
    "* [Components of a NetCDF Dataset](https://iprc.soest.hawaii.edu/users/xfu/tool/guidef-7.html#)\n",
    "* [Network Common Data Form (NetCDF)](https://www.unidata.ucar.edu/software/netcdf/) and [A Brief History of (netCDF) Time](https://www.unidata.ucar.edu/software/netcdf/time/recs.html)\n",
    "\n",
    "\n",
    "\n",
    "### Xarray essentials\n",
    "Earlier we introduced the xarray pacakge and used `open_dataset` and `open_mfdataset` to retrieve NetCDF data file as an xarray Dataset object. Recall that you can review the data in a notebook by using `print(ds)` or `ds`. \n",
    "\n",
    "Using xarray to retrieve the aforementioned NetCDF basics is straightforwared. In general,\n",
    "* Dataset: `ds`\n",
    "* Data array: `ds.variables`\n",
    "* Variable: `ds.ds.variables`\n",
    "* Dimenssion: `ds.dims`\n",
    "* Coordinate: `ds.coords`\n",
    "* Data Type: `type`\n",
    "* Meta Data (Attributes)\n",
    "\n",
    "Also, here are some references if you are new to xarray\n",
    "* [Xarray in 45 minutes](https://tutorial.xarray.dev/overview/xarray-in-45-min.html)\n",
    "* [Handling NetCDF Files using XArray for Absolute Beginners](https://towardsdatascience.com/handling-netcdf-files-using-xarray-for-absolute-beginners-111a8ab4463f)\n",
    "\n",
    "Try the following commands in action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eac323",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ecf85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset \n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data array, Variable\n",
    "# Note: the info can be overwhelming. Do not attempt to grasp everything at the first glance.\n",
    "ds.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c41b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimenssions\n",
    "ds.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinates\n",
    "ds.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d6064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta Data (Attributes)\n",
    "ds.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "print(type(ds))\n",
    "print(type(ds.variables))\n",
    "print(type(ds.dims))\n",
    "print(type(ds.coords))\n",
    "print(type(ds.attrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643399d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus: retrieve variable names only\n",
    "list(ds.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf36878",
   "metadata": {},
   "source": [
    "#### Discussion: variable vs. coordinates vs. dimenssions. \n",
    "From [Components of a NetCDF Dataset](https://iprc.soest.hawaii.edu/users/xfu/tool/guidef-7.html#):\n",
    "\n",
    "* Dimession: A dimension may be used to represent a real physical dimension, for example, time, latitude, longitude, or height. A dimension might also be used to index other quantities, for example station or model-run-number.\n",
    "A netCDF dimension has both a name and a length. A dimension length is an arbitrary positive integer, except that one dimension in a netCDF dataset can have the length UNLIMITED.\n",
    "\n",
    "* Variables: Variables are used to store the bulk of the data in a netCDF dataset. A variable represents an array of values of the same type. A scalar value is treated as a 0-dimensional array. A variable has a name, a data type, and a shape described by its list of dimensions specified when the variable is created. A variable may also have associated attributes, which may be added, deleted or changed after the variable is created.\n",
    "\n",
    "* Coordinate (Variables): It is legal for a variable to have the same name as a dimension. Such variables have no special meaning to the netCDF library. However there is a convention that such variables should be treated in a special way by software using this library.\n",
    "A variable with the same name as a dimension is called a coordinate variable. It typically defines a physical coordinate corresponding to that dimension.\n",
    "\n",
    "\n",
    "Tips: By definition, coordinates and dimenssions are also variable. For example ds.time is a coordinate but it is also a special variable. But in practice, when we talk about variable, it implies regular/non-coordinate variable. We will use this convention for the remaining notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47120f9",
   "metadata": {},
   "source": [
    "### Xarray Variable\n",
    "\n",
    "\n",
    "We can use `ds.variables` to access varialbes of a dataset. But many times viewing print-out the whole datasets can be overwhemling. Instead, we would work on the individual variable (also called Xarray data array.) using the `ds[var_name]` syntax, where `var_name` is the name of the variable. See the following examples in action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(ds[\"time\"]))\n",
    "ds[\"time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec643e",
   "metadata": {},
   "source": [
    "#### Variable properties\n",
    "For individual varible, the following properties are mostly used with the assocaited xarray method to retrieve them. (assuming var = ds[var_name])\n",
    "* name: `var.name`\n",
    "* data content: `var.data`\n",
    "* attributes: `var.attrs`\n",
    "* dimenstions: `var.dims`\n",
    "* data type: `var.data.dtype`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a632a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = \"time\"\n",
    "var = ds[var_name]\n",
    "\n",
    "print(\"var.name: \\n\", var.name, \"\\n\")\n",
    "print(\"var.data: \\n\", var.data, \"\\n\")\n",
    "print(\"var.attrs: \\n\", var.attrs, \"\\n\")\n",
    "print(\"var.dims: \\n\", var.dims, \"\\n\")\n",
    "print(\"var.data.dtype: \\n\", var.data.dtype, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b256b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus: indivdual variable info table (collect and display variable info as a tabular format)\n",
    "df_info = pd.DataFrame()\n",
    "df_info[\"var_name\"] = list(ds.variables)\n",
    "df_info[\"dims\"] = df_info.var_name.apply(lambda x: ds[x].dims)\n",
    "df_info[\"is_dim\"] = df_info.var_name.apply(lambda x: x in ds.dims)\n",
    "df_info[\"n_dim\"] = df_info.var_name.apply(lambda x: len(ds[x].dims))\n",
    "df_info[\"attrs\"] = df_info.var_name.apply(lambda x: ds[x].attrs)\n",
    "df_info[\"dtype\"] = df_info.var_name.apply(lambda x: ds[x].data.dtype)\n",
    "df_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a36b96",
   "metadata": {},
   "source": [
    "### Data cleaning/Preprocessing (skipped)\n",
    "Data cleaning and preprocessing is an important stage in the the data analysis pipeline. However it will be out of the scope of this notebook. For more information about data cleaning and preprocessing basics, here are some references. \n",
    "* [Xarray Fundamentals](https://earth-env-data-science.github.io/lectures/xarray/xarray.html)\n",
    "* [Xarray Tutorial â€” Pangeo Gallery documentation](http://gallery.pangeo.io/repos/pangeo-data/pangeo-tutorial-gallery/xarray.html)\n",
    "* [Pythonic Data Cleaning With pandas and NumPy](https://realpython.com/python-data-cleaning-numpy-pandas/)\n",
    "* [Pandas - Cleaning Data](https://www.w3schools.com/python/pandas/pandas_cleaning.asp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e1a69",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "Data visualization (or plotting) is another important data analysis topic and deserves its own discussion. Here in this notebook we will only demonstrate basic tool for simple data visualization tasks.\n",
    "\n",
    "Here are some reference you might find useful:\n",
    "* xarray plotting: https://docs.xarray.dev/en/stable/user-guide/plotting.html\n",
    "* Atmospheric Community Toolkit (ACT): https://arm-doe.github.io/ACT/index.html\n",
    "\n",
    "Note: this notebook is auto-generated using a template. It uses a general idea to select variable(s) to plot and is not customized to each indivdual notebook. Feel free to change the variables in intrrests, especially certain figure is failed to plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e417fb2",
   "metadata": {},
   "source": [
    "#### 1-dimenssional basic time series plot\n",
    "\n",
    "For the following plot we would like to find variables such that\n",
    "* it has one and only one dimession\n",
    "* \"time\" is its coordinate variable\n",
    "* it is not a dimenssion itself,\n",
    "* it is not a special variable with substrings within [\"time\", \"lat\", \"lon\", \"alt\", \"qc\"]\n",
    "\n",
    "Please see the following example in action. (For more details about pandas filtering, please see the following references.)\n",
    "* [pandas: multiple conditions while indexing data frame](https://stackoverflow.com/questions/22591174/pandas-multiple-conditions-while-indexing-data-frame-unexpected-behavior)\n",
    "* [pandas.DataFrame.apply](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html)\n",
    "* [How to test if a string contains one of the substrings in a list...](https://stackoverflow.com/questions/26577516/how-to-test-if-a-string-contains-one-of-the-substrings-in-a-list-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30edac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (pandas query) filter n_dim==1, non-dimenssional, and not contains the following substrings\n",
    "exclude_substrings = [\"time\", \"lat\", \"lon\", \"alt\", \"qc\"]\n",
    "df_filter = df_info[(df_info.n_dim == 1) &\n",
    "                    (df_info.dims.apply(lambda x: \"time\" in x)) &\n",
    "                    (df_info.is_dim==False) &\n",
    "                    (~df_info.var_name.str.contains('|'.join(exclude_substrings)))\n",
    "                   ]\n",
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    var_1d = df_filter.var_name.values[0]\n",
    "    var_1d\n",
    "except Exception as e:\n",
    "    print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ae985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: if failed, change to another variable to plot.\n",
    "try:\n",
    "    ds[var_1d].plot()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(e)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e41066e",
   "metadata": {},
   "source": [
    "#### 2-dimenssional basic plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd4adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (pandas query) filter n_dim==2, non-dimenssional, and not contains the following substrings\n",
    "exclude_substrings = [\"time\", \"lat\", \"lon\", \"alt\", \"qc\"]\n",
    "df_filter_2 = df_info[(df_info.n_dim == 2) &\n",
    "                      (df_info.dims.apply(lambda x: \"time\" in x)) &\n",
    "                      (df_info.is_dim==False) &\n",
    "                      (~df_info.var_name.str.contains('|'.join(exclude_substrings)))\n",
    "                     ]\n",
    "df_filter_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdea1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    var_2d = df_filter_2.var_name.values[0]\n",
    "    var_2d\n",
    "except Exception as e:\n",
    "    print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f48879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: if failed, change to another variable to plot.\n",
    "try:\n",
    "    print(ds[var_2d].dims)\n",
    "    # ds[var_2d].plot()\n",
    "\n",
    "    # conventionally, use \"time\" as x-axis\n",
    "    ds[var_2d].plot(x=\"time\")\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(e)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554b2a6",
   "metadata": {},
   "source": [
    "#### qc-plotting (optional)\n",
    "\n",
    "Note: act qc plotting has more strict requirement, one of them is the associated qc variable need to have \"flag_masks\" attributes. Which is added by using ds = act.io.armfiles.read_netcdf(files_list), then ds.clean.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c2096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ds_act = act.io.armfiles.read_netcdf(full_path)\n",
    "    print(type(ds_act))\n",
    "    ds_act.clean.cleanup()\n",
    "\n",
    "    # or \n",
    "    # ds.clean.cleanup()\n",
    "except Exception as e:\n",
    "    print(\"ERROR\", e)\n",
    "    ds_act = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter valid variables for ACT qc plotting\n",
    "condition = (\"qc_\" + df_info.var_name).apply(lambda x: ds_act[x].attrs.get(\"flag_masks\") is not None \n",
    "                                             if x in list(ds.variables) else False)\n",
    "exclude_substrings = [\"time\", \"lat\", \"lon\", \"alt\", \"qc\"]\n",
    "df_filter_3 = df_info[(df_info.is_dim==False) &\n",
    "                      (df_info.dims.apply(lambda x: \"time\" in x)) &\n",
    "                      (~df_info.var_name.str.contains('|'.join(exclude_substrings))) &\n",
    "                      condition\n",
    "       ]\n",
    "df_filter_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd38cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC Plot\n",
    "try:\n",
    "    qc_variable = df_filter_3.var_name.values[0]\n",
    "    print(qc_variable)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "try:\n",
    "\n",
    "    # Plot\n",
    "    qc_display = act.plotting.TimeSeriesDisplay(ds_act)\n",
    "    qc_display.add_subplots((2,), figsize = (9.5,10))\n",
    "    qc_ax = qc_display.plot(qc_variable, subplot_index=(0,), set_title=\"QC results on field: \" + qc_variable,)\n",
    "    qc_ax.grid()\n",
    "    qc_display.qc_flag_block_plot(qc_variable, subplot_index=(1,))\n",
    "    qc_ax.set_xlabel(f\"UTC Time starts at {ds.time.data[0]}\")\n",
    "\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e4d27",
   "metadata": {},
   "source": [
    "#### bonus: choose variables to plot from a dropdown menu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb733804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid variables filtering\n",
    "exclude_substrings = [\"time\", \"lat\", \"lon\", \"alt\", \"qc\"]\n",
    "df_filter_4 = df_info[(df_info.is_dim==False) &\n",
    "                      (df_info.dims.apply(lambda x: \"time\" in x)) &\n",
    "                      (~df_info.var_name.str.contains('|'.join(exclude_substrings)))\n",
    "                     ]\n",
    "df_filter_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d5c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example 1: using xarray plot\n",
    "\n",
    "# Uncomment the following cell to try the interactive plot (ctrl + /)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc9aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "# plt.clf()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# available_variables = df_filter_4.var_name.values\n",
    "# @widgets.interact(var=available_variables)\n",
    "# def update(var = available_variables[0]):\n",
    "#     fig.clear() # Remove old lines from plot and plot new one\n",
    "#     if len(ds[var].dims)==2:\n",
    "#         ds[var].plot(x=\"time\", add_colorbar=False)\n",
    "#     else:\n",
    "#         ds[var].plot()\n",
    "#     plt.grid()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabdd802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example 2: using act plot\n",
    "\n",
    "# Uncomment the following cell to try the interactive plot (ctrl + /)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "# plt.clf()\n",
    "\n",
    "# available_variables = df_filter_4.var_name.values\n",
    "\n",
    "\n",
    "# @widgets.interact(var=available_variables)\n",
    "# def update(var = available_variables[0]):\n",
    "\n",
    "#     i_display = act.plotting.TimeSeriesDisplay(ds_act)\n",
    "#     i_display.add_subplots((1,), figsize=(10, 4))\n",
    "#     ax = i_display.plot(var, subplot_index=(0,), set_title=f\"{var} ({ds_act[var].attrs['long_name']})\",)\n",
    "\n",
    "#     ax.set_xlabel(f\"UTC Time starts at {ds.time.data[0]}\")\n",
    "#     ax.grid()\n",
    "#     plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
